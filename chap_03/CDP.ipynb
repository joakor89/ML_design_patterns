{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Cascade Design Pattern**\n",
        "\n",
        "### ***Loading Libraries***"
      ],
      "metadata": {
        "id": "J891oG28XriP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dICF4SpDUdoX"
      },
      "outputs": [],
      "source": [
        "# Operating Systems\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from typing import NamedTuple\n",
        "\n",
        "# Numerical Computing\n",
        "import numpy as np\n",
        "\n",
        "# Data Manipuation\n",
        "import pandas as pd\n",
        "\n",
        "# JavaScript Object Notation\n",
        "import json\n",
        "\n",
        "# SciPy\n",
        "import scipy\n",
        "from scipy import stats\n",
        "\n",
        "# Data Visualization\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# BigQuery\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "\n",
        "# Scikit-Learn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Extreme Gradient Boosting\n",
        "import xgboost as xgb\n",
        "\n",
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow_hub import KerasLayer\n",
        "from tensorflow import feature_column as fc\n",
        "from tensorflow.keras.preprocessing import text\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import callbacks, layers, models, utils\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Embedding, Input, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "import kfp\n",
        "import kfp.dsl as dsl\n",
        "import kfp.components as comp\n",
        "import kfp.compiler as compiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# User Authentication\n",
        "auth.authenticate_user()\n",
        "\n",
        "# BigQuery Library\n",
        "# !pip install --upgrade google-cloud-bigquery"
      ],
      "metadata": {
        "id": "lci_BURDY3Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID='ai-analytics-solutions'\n",
        "\n",
        "KFPHOST='20844794c6e37538-dot-us-central2.pipelines.googleusercontent.com' # from settings button in CAIP Pipelines"
      ],
      "metadata": {
        "id": "-FD0sYskY3d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Retrieving Data***"
      ],
      "metadata": {
        "id": "BAJYeoY8Zj9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Retrieiving & Downloading\n",
        "!bq show mlpatterns || bq mk mlpatterns"
      ],
      "metadata": {
        "id": "swgZzLwgZmey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigquery_query_op = comp.load_component_from_url(\n",
        "    'https://raw.githubusercontent.com/kubeflow/pipelines/0e794e8a0eff6f81ddc857946ee8311c7c431ec2/components/gcp/bigquery/query/component.yaml')\n",
        "help(bigquery_query_op)"
      ],
      "metadata": {
        "id": "LTjt3W-AZzcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def run_bigquery_ddl(project_id: str, query_string: str, location: str) -> NamedTuple(\n",
        "    'DDLOutput', [('created_table', str), ('query', str)]):\n",
        "    \"\"\"\n",
        "    Runs BigQuery query and returns a table/model name\n",
        "    \"\"\"\n",
        "    print(query_string)\n",
        "\n",
        "    from google.cloud import bigquery\n",
        "    from google.api_core.future import polling\n",
        "    from google.cloud import bigquery\n",
        "    from google.cloud.bigquery import retry as bq_retry\n",
        "\n",
        "    bqclient = bigquery.Client(project=project_id, location=location)\n",
        "    job = bqclient.query(query_string, retry=bq_retry.DEFAULT_RETRY)\n",
        "    job._retry = polling.DEFAULT_RETRY\n",
        "\n",
        "    while job.running():\n",
        "        from time import sleep\n",
        "        sleep(0.1)\n",
        "        print('Running ...')\n",
        "\n",
        "    tblname = job.ddl_target_table\n",
        "    tblname = '{}.{}'.format(tblname.dataset_id, tblname.table_id)\n",
        "    print('{} created in {}'.format(tblname, job.ended - job.started))\n",
        "\n",
        "    from collections import namedtuple\n",
        "    result_tuple = namedtuple('DDLOutput', ['created_table', 'query'])\n",
        "    return result_tuple(tblname, query_string)\n",
        "\n",
        "\n",
        "def train_classification_model(ddlop, project_id):\n",
        "    query = \"\"\"\n",
        "        CREATE OR REPLACE MODEL mlpatterns.classify_trips\n",
        "        TRANSFORM(\n",
        "          trip_type,\n",
        "          EXTRACT (HOUR FROM start_date) AS start_hour,\n",
        "          EXTRACT (DAYOFWEEK FROM start_date) AS day_of_week,\n",
        "          start_station_name,\n",
        "          subscriber_type,\n",
        "          ML.QUANTILE_BUCKETIZE(member_birth_year, 10) OVER() AS bucketized_age,\n",
        "          member_gender\n",
        "        )\n",
        "        OPTIONS(model_type='logistic_reg',\n",
        "                auto_class_weights=True,\n",
        "                input_label_cols=['trip_type']) AS\n",
        "\n",
        "        SELECT\n",
        "          start_date, start_station_name, subscriber_type, member_birth_year, member_gender,\n",
        "          IF(duration_sec > 3600*4, 'Long', 'Typical') AS trip_type\n",
        "        FROM `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips`\n",
        "    \"\"\"\n",
        "    print(query)\n",
        "    return ddlop(project_id, query, 'US')\n",
        "\n",
        "def create_training_data(ddlop, project_id, model_name, segment):\n",
        "    query = \"\"\"\n",
        "        CREATE OR REPLACE TABLE mlpatterns.{0}_trips AS\n",
        "        SELECT\n",
        "          * EXCEPT(predicted_trip_type_probs, predicted_trip_type)\n",
        "        FROM\n",
        "        ML.PREDICT(MODEL {1}, -- mlpatterns.classify_trips\n",
        "          (SELECT\n",
        "          start_date, start_station_name, subscriber_type, member_birth_year, member_gender,\n",
        "          ST_Distance(start_station_geom, end_station_geom) AS distance\n",
        "          FROM `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips`)\n",
        "        )\n",
        "        WHERE predicted_trip_type = '{0}' AND distance IS NOT NULL\n",
        "    \"\"\".format(segment, model_name)\n",
        "    print(query)\n",
        "    return ddlop(project_id, query, 'US')\n",
        "\n",
        "def train_distance_model(ddlop, project_id, train_table_name, segment):\n",
        "    query = \"\"\"\n",
        "        CREATE OR REPLACE MODEL mlpatterns.predict_distance_{0}\n",
        "        TRANSFORM(\n",
        "          distance,\n",
        "          EXTRACT (HOUR FROM start_date) AS start_hour,\n",
        "          EXTRACT (DAYOFWEEK FROM start_date) AS day_of_week,\n",
        "          start_station_name,\n",
        "          subscriber_type,\n",
        "          ML.QUANTILE_BUCKETIZE(member_birth_year, 10) OVER() AS bucketized_age,\n",
        "          member_gender\n",
        "        )\n",
        "        OPTIONS(model_type='linear_reg', input_label_cols=['distance']) AS\n",
        "\n",
        "        SELECT\n",
        "          *\n",
        "        FROM\n",
        "          {1} -- mlpatterns.{0}_trips\n",
        "\n",
        "    \"\"\".format(segment, train_table_name)\n",
        "    print(query)\n",
        "    return ddlop(project_id, query, 'US')\n",
        "\n",
        "\n",
        "def evaluate(project_id: str,\n",
        "             classification_model: str, typical_trip_model: str, long_trip_model: str) -> float:\n",
        "    query = \"\"\"\n",
        "        WITH input_data AS (\n",
        "           SELECT start_date, start_station_name, subscriber_type, member_birth_year, member_gender,\n",
        "                  ST_Distance(start_station_geom, end_station_geom) AS distance\n",
        "           FROM `bigquery-public-data.san_francisco_bikeshare.bikeshare_trips`\n",
        "        ),\n",
        "\n",
        "        classified AS (\n",
        "        SELECT\n",
        "          * EXCEPT(predicted_trip_type_probs)\n",
        "        FROM ML.PREDICT(\n",
        "          MODEL {0},\n",
        "          (SELECT * from input_data)\n",
        "        )\n",
        "        ),\n",
        "\n",
        "        evals AS (\n",
        "\n",
        "        SELECT\n",
        "          distance, predicted_distance\n",
        "        FROM ML.PREDICT(\n",
        "          MODEL {1},\n",
        "          (SELECT * from classified WHERE predicted_trip_type = 'Typical')\n",
        "        )\n",
        "        UNION ALL\n",
        "        SELECT\n",
        "          distance, predicted_distance\n",
        "        FROM ML.PREDICT(\n",
        "          MODEL {2},\n",
        "          (SELECT * from classified WHERE predicted_trip_type = 'Long')\n",
        "        )\n",
        "\n",
        "        )\n",
        "\n",
        "        SELECT\n",
        "           APPROX_QUANTILES(ABS(distance - predicted_distance), 10)[OFFSET(5)] AS median_absolute_error\n",
        "        FROM\n",
        "           evals\n",
        "    \"\"\".format(classification_model, typical_trip_model, long_trip_model)\n",
        "    print(query)\n",
        "    from google.cloud import bigquery\n",
        "    bqclient = bigquery.Client(project=project_id, location='US')\n",
        "    df = bqclient.query(query).result().to_dataframe()\n",
        "    return df['median_absolute_error'][0]\n",
        "\n",
        "\n",
        "@dsl.pipeline(\n",
        "    name='Cascade pipeline on SF bikeshare',\n",
        "    description='Cascade pipeline on SF bikeshare'\n",
        ")\n",
        "def cascade_pipeline(\n",
        "    project_id = PROJECT_ID\n",
        "):\n",
        "    ddlop = comp.func_to_container_op(run_bigquery_ddl, packages_to_install=['google-cloud-bigquery'])\n",
        "\n",
        "    c1 = train_classification_model(ddlop, PROJECT_ID)\n",
        "    c1_model_name = c1.outputs['created_table']\n",
        "\n",
        "    c2a_input = create_training_data(ddlop, PROJECT_ID, c1_model_name, 'Typical')\n",
        "    c2b_input = create_training_data(ddlop, PROJECT_ID, c1_model_name, 'Long')\n",
        "\n",
        "    c3a_model = train_distance_model(ddlop, PROJECT_ID, c2a_input.outputs['created_table'], 'Typical')\n",
        "    c3b_model = train_distance_model(ddlop, PROJECT_ID, c2b_input.outputs['created_table'], 'Long')\n",
        "\n",
        "    evalop = comp.func_to_container_op(evaluate, packages_to_install=['google-cloud-bigquery', 'pandas'])\n",
        "    error = evalop(PROJECT_ID, c1_model_name, c3a_model.outputs['created_table'], c3b_model.outputs['created_table'])\n",
        "    print(error.output)"
      ],
      "metadata": {
        "id": "bC3IvpJxaR-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_func = cascade_pipeline\n",
        "\n",
        "pipeline_filename = pipeline_func.__name__ + '.zip'\n",
        "\n",
        "compiler.Compiler().compile(pipeline_func, pipeline_filename)\n",
        "\n",
        "arguments = {}\n",
        "\n",
        "client = kfp.Client(KFPHOST)\n",
        "experiment = client.create_experiment('cascade_experiment')\n",
        "\n",
        "# Running Pipeline\n",
        "run_name = pipeline_func.__name__ + ' run'\n",
        "run_result = client.run_pipeline(experiment.id, run_name, pipeline_filename, arguments)"
      ],
      "metadata": {
        "id": "eXglsAkyaUZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}