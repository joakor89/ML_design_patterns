{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Distribution Strategy Design Pattern**\n",
        "\n",
        "### ***Loading Libraries***"
      ],
      "metadata": {
        "id": "LPhhFiD1jPBc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ujOc7wkejLVi"
      },
      "outputs": [],
      "source": [
        "# Operating Systems\n",
        "import os\n",
        "import shutil\n",
        "import datetime\n",
        "\n",
        "# Numerical Computing\n",
        "import numpy as np\n",
        "\n",
        "# Data Manipuation\n",
        "import pandas as pd\n",
        "\n",
        "# SciPy\n",
        "import scipy\n",
        "from scipy import stats\n",
        "\n",
        "# Data Visualization\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# BigQuery\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "\n",
        "# Scikit-Learn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Extreme Gradient Boosting\n",
        "import xgboost as xgb\n",
        "\n",
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow_hub import KerasLayer\n",
        "from tensorflow import feature_column as fc\n",
        "from tensorflow.keras.preprocessing import text\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import callbacks, layers, models, utils\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Embedding, Input, Flatten, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_COLUMNS = [\"weight_pounds\",\n",
        "               \"is_male\",\n",
        "               \"mother_age\",\n",
        "               \"plurality\",\n",
        "               \"gestation_weeks\",\n",
        "               \"mother_race\"]\n",
        "\n",
        "# Add string name for label column\n",
        "LABEL_COLUMN = \"weight_pounds\"\n",
        "\n",
        "# Set default values for each CSV column as a list of lists.\n",
        "# Treat is_male and plurality as strings.\n",
        "DEFAULTS = [[0.0], [\"null\"], [0.0], [\"null\"], [0.0], [\"null\"]]"
      ],
      "metadata": {
        "id": "8NFv4rbBjl6z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def features_and_labels(row_data):\n",
        "    \"\"\"Splits features and labels from feature dictionary.\n",
        "    Args:\n",
        "        row_data: Dictionary of CSV column names and tensor values.\n",
        "    Returns:\n",
        "        Dictionary of feature tensors and label tensor.\n",
        "    \"\"\"\n",
        "    label = row_data.pop(LABEL_COLUMN)\n",
        "\n",
        "    return row_data, label\n",
        "\n",
        "\n",
        "def load_dataset(pattern, batch_size=1, mode=tf.estimator.ModeKeys.EVAL):\n",
        "    \"\"\"Loads dataset using the tf.data API from CSV files.\n",
        "    Args:\n",
        "        pattern: str, file pattern to glob into list of files.\n",
        "        batch_size: int, the number of examples per batch.\n",
        "        mode: tf.estimator.ModeKeys to determine if training or evaluating.\n",
        "    Returns:\n",
        "        `Dataset` object.\n",
        "    \"\"\"\n",
        "    # Make a CSV dataset\n",
        "    dataset = tf.data.experimental.make_csv_dataset(\n",
        "        file_pattern=pattern,\n",
        "        batch_size=batch_size,\n",
        "        column_names=CSV_COLUMNS,\n",
        "        column_defaults=DEFAULTS)\n",
        "\n",
        "    # Map dataset to features and label\n",
        "    dataset = dataset.map(map_func=features_and_labels)  # features, label\n",
        "\n",
        "    # Shuffle and repeat for training\n",
        "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        dataset = dataset.shuffle(buffer_size=1000).repeat()\n",
        "\n",
        "    # Take advantage of multi-threading; 1=AUTOTUNE\n",
        "    dataset = dataset.prefetch(buffer_size=1)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "MmPzCI_Qjl4X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Building as Previous Model***"
      ],
      "metadata": {
        "id": "edxEHTJgkcS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_input_layers():\n",
        "    \"\"\"Creates dictionary of input layers for each feature.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary of `tf.Keras.layers.Input` layers for each feature.\n",
        "    \"\"\"\n",
        "    inputs = {\n",
        "        colname: tf.keras.layers.Input(\n",
        "            name=colname, shape=(), dtype=\"float32\")\n",
        "        for colname in [\"mother_age\", \"gestation_weeks\"]}\n",
        "\n",
        "    inputs.update({\n",
        "        colname: tf.keras.layers.Input(\n",
        "            name=colname, shape=(), dtype=\"string\")\n",
        "        for colname in [\"is_male\", \"plurality\", \"mother_race\"]})\n",
        "\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "HRpG4Pavjl19"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Feature's Column Set-Up***"
      ],
      "metadata": {
        "id": "555b6SjRkk0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorical_fc(name, values):\n",
        "    cat_column = fc.categorical_column_with_vocabulary_list(\n",
        "            key=name, vocabulary_list=values)\n",
        "\n",
        "    return fc.indicator_column(categorical_column=cat_column)\n",
        "\n",
        "\n",
        "def create_feature_columns():\n",
        "    feature_columns = {\n",
        "        colname : fc.numeric_column(key=colname)\n",
        "           for colname in [\"mother_age\", \"gestation_weeks\"]\n",
        "    }\n",
        "\n",
        "    feature_columns[\"is_male\"] = categorical_fc(\n",
        "        \"is_male\", [\"True\", \"False\", \"Unknown\"])\n",
        "    feature_columns[\"plurality\"] = categorical_fc(\n",
        "        \"plurality\", [\"Single(1)\", \"Twins(2)\", \"Triplets(3)\",\n",
        "                      \"Quadruplets(4)\", \"Quintuplets(5)\", \"Multiple(2+)\"])\n",
        "    feature_columns[\"mother_race\"] = fc.indicator_column(\n",
        "        fc.categorical_column_with_hash_bucket(\n",
        "            \"mother_race\", hash_bucket_size=17, dtype=tf.dtypes.string))\n",
        "\n",
        "    feature_columns[\"gender_x_plurality\"] = fc.embedding_column(\n",
        "        fc.crossed_column([\"is_male\", \"plurality\"], hash_bucket_size=18),\n",
        "        dimension=2)\n",
        "\n",
        "    return feature_columns"
      ],
      "metadata": {
        "id": "4nu_EaB1jlzf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_outputs(inputs):\n",
        "    h1 = layers.Dense(64, activation=\"relu\", name=\"h1\")(inputs)\n",
        "    h2 = layers.Dense(32, activation=\"relu\", name=\"h2\")(h1)\n",
        "\n",
        "    output = layers.Dense(units=1, activation=\"linear\", name=\"weight\")(h2)\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "yf0z5U7ljlxC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    return tf.sqrt(tf.reduce_mean((y_pred - y_true) ** 2))"
      ],
      "metadata": {
        "id": "ODyH1g4Sjlun"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Build & Set-Up Distribution Strategy**"
      ],
      "metadata": {
        "id": "hJYp5aTjkHBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dnn_model():\n",
        "    \"\"\"Builds simple DNN using Keras Functional API.\n",
        "\n",
        "    Returns:\n",
        "        `tf.keras.models.Model` object.\n",
        "    \"\"\"\n",
        "    # Input Layer\n",
        "    inputs = create_input_layers()\n",
        "\n",
        "    # Feature columns\n",
        "    feature_columns = create_feature_columns()\n",
        "\n",
        "    dnn_inputs = layers.DenseFeatures(\n",
        "        feature_columns=feature_columns.values())(inputs)\n",
        "\n",
        "    # Output\n",
        "    output = get_model_outputs(dnn_inputs)\n",
        "\n",
        "    # Setting Model\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
        "    # Compiling Model\n",
        "    model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[rmse, \"mse\"])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Distribution Strategy\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "\n",
        "with mirrored_strategy.scope():\n",
        "    model = build_dnn_model()\n",
        "\n",
        "print(\"Here is our DNN architecture so far:\\n\")\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MOpklYqjlr5",
        "outputId": "3db87b80-e4c0-4cda-affc-3ca9726e4ad7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-3c41f3e946f6>:10: numeric_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-5-3c41f3e946f6>:2: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-5-3c41f3e946f6>:5: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-5-3c41f3e946f6>:20: categorical_column_with_hash_bucket (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-5-3c41f3e946f6>:24: crossed_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.keras.layers.experimental.preprocessing.HashedCrossing` instead for feature crossing when preprocessing data to train a Keras model.\n",
            "WARNING:tensorflow:From <ipython-input-5-3c41f3e946f6>:23: embedding_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here is our DNN architecture so far:\n",
            "\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " gestation_weeks (InputLaye  [(None,)]                    0         []                            \n",
            " r)                                                                                               \n",
            "                                                                                                  \n",
            " is_male (InputLayer)        [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " mother_age (InputLayer)     [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " mother_race (InputLayer)    [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " plurality (InputLayer)      [(None,)]                    0         []                            \n",
            "                                                                                                  \n",
            " dense_features (DenseFeatu  (None, 30)                   36        ['gestation_weeks[0][0]',     \n",
            " res)                                                                'is_male[0][0]',             \n",
            "                                                                     'mother_age[0][0]',          \n",
            "                                                                     'mother_race[0][0]',         \n",
            "                                                                     'plurality[0][0]']           \n",
            "                                                                                                  \n",
            " h1 (Dense)                  (None, 64)                   1984      ['dense_features[0][0]']      \n",
            "                                                                                                  \n",
            " h2 (Dense)                  (None, 32)                   2080      ['h1[0][0]']                  \n",
            "                                                                                                  \n",
            " weight (Dense)              (None, 1)                    33        ['h2[0][0]']                  \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4133 (16.14 KB)\n",
            "Trainable params: 4133 (16.14 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of devices: {}'.format(mirrored_strategy.num_replicas_in_sync))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lm5AKzsnkXQd",
        "outputId": "e78c67b2-21ec-4d96-95ab-3c221fa41498"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of devices: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hN3X8WdZn_qn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}