{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Over-Fitting Desing**\n",
        "\n",
        "### ***Loading Libraries***"
      ],
      "metadata": {
        "id": "tijjf0Kcru_X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NEdnv8PMrstB"
      },
      "outputs": [],
      "source": [
        "# Operating Systems\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# Numerical Computing\n",
        "import numpy as np\n",
        "\n",
        "# Data Manipuation\n",
        "import pandas as pd\n",
        "\n",
        "# SciPy\n",
        "import scipy\n",
        "from scipy import stats\n",
        "\n",
        "# Data Visualization\n",
        "import itertools\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# BigQuery\n",
        "from google.cloud import bigquery\n",
        "from google.colab import auth\n",
        "\n",
        "# Scikit-Learn\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Extreme Gradient Boosting\n",
        "import xgboost as xgb\n",
        "\n",
        "# TensorFlow\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Model\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow_hub import KerasLayer\n",
        "from tensorflow import feature_column as fc\n",
        "from tensorflow.keras.preprocessing import text\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import callbacks, layers, models, utils\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Dense, Embedding, Input, Flatten, Conv2D, MaxPooling2D"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Loading Data***"
      ],
      "metadata": {
        "id": "LhDu9B4Bt8K6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/babyweight_train.csv\")"
      ],
      "metadata": {
        "id": "Z7Q87yXTt-i2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***Model Features Set-Up***"
      ],
      "metadata": {
        "id": "zppyU4F4ukMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.is_male = df.is_male.astype(str)\n",
        "df.mother_race.fillna(0, inplace=True)\n",
        "df.mother_race = df.mother_race.astype(str)\n",
        "\n",
        "FEATURES = ['is_male', 'mother_age', 'plurality', 'gestation_weeks', 'mother_race']\n",
        "LABEL = ['weight_pounds']\n",
        "\n",
        "N_TRAIN = int(df.shape[0] * 0.80)\n",
        "\n",
        "X_train = df[FEATURES][:N_TRAIN]\n",
        "X_valid = df[FEATURES][N_TRAIN:]\n",
        "y_train = df[LABEL][:N_TRAIN]\n",
        "y_valid = df[LABEL][N_TRAIN:]\n",
        "\n",
        "X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(0).astype('float32')\n",
        "X_valid = X_valid.apply(pd.to_numeric, errors='coerce').fillna(0).astype('float32')\n",
        "y_train = y_train.astype('float32')\n",
        "y_valid = y_valid.astype('float32')\n",
        "\n",
        "X_train_array = X_train.to_numpy()\n",
        "y_train_array = y_train.to_numpy()\n",
        "X_valid_array = X_valid.to_numpy()\n",
        "y_valid_array = y_valid.to_numpy()"
      ],
      "metadata": {
        "id": "qawyR4e6xAlV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Input Pipeline"
      ],
      "metadata": {
        "id": "yJElq1E4uyib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train/Validation Dataset\n",
        "trainds = tf.data.Dataset.from_tensor_slices((X_train_array, y_train_array))\n",
        "\n",
        "evalds = tf.data.Dataset.from_tensor_slices((X_valid_array, y_valid_array))"
      ],
      "metadata": {
        "id": "-NzN59G1umI4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "trainds = trainds.shuffle(buffer_size=len(X_train)).batch(BATCH_SIZE)\n",
        "evalds = evalds.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "q-lbe97byMEi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the datasets\n",
        "for dict_slice in trainds.take(1):\n",
        "    print(\"{}\\n\".format(dict_slice))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCrAyfXNumGB",
        "outputId": "5244ff83-61c0-4559-eddd-fafadfb861d0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(32, 5), dtype=float32, numpy=\n",
            "array([[ 0., 19.,  0., 33.,  0.],\n",
            "       [ 0., 20.,  0., 37.,  1.],\n",
            "       [ 0., 19.,  0., 39.,  0.],\n",
            "       [ 0., 19.,  0., 41.,  2.],\n",
            "       [ 0., 20.,  0., 36.,  1.],\n",
            "       [ 0., 20.,  0., 37.,  0.],\n",
            "       [ 0., 20.,  0., 39.,  1.],\n",
            "       [ 0., 18.,  0., 38.,  1.],\n",
            "       [ 0., 17.,  0., 40.,  1.],\n",
            "       [ 0., 18.,  0., 40.,  1.],\n",
            "       [ 0., 17.,  0., 38.,  0.],\n",
            "       [ 0., 19.,  0., 39.,  2.],\n",
            "       [ 0., 20.,  0., 40.,  1.],\n",
            "       [ 0., 19.,  0., 41.,  0.],\n",
            "       [ 0., 19.,  0., 37.,  1.],\n",
            "       [ 0., 20.,  0., 39.,  0.],\n",
            "       [ 0., 20.,  0., 41.,  1.],\n",
            "       [ 0., 18.,  0., 38.,  1.],\n",
            "       [ 0., 20.,  0., 40.,  1.],\n",
            "       [ 0., 19.,  0., 41.,  0.],\n",
            "       [ 0., 20.,  0., 38.,  1.],\n",
            "       [ 0., 18.,  0., 31.,  0.],\n",
            "       [ 0., 20.,  0., 45.,  1.],\n",
            "       [ 0., 20.,  0., 31.,  1.],\n",
            "       [ 0., 17.,  0., 36.,  1.],\n",
            "       [ 0., 18.,  0., 41.,  1.],\n",
            "       [ 0., 20.,  0., 39.,  1.],\n",
            "       [ 0., 18.,  0., 40.,  1.],\n",
            "       [ 0., 20.,  0., 41.,  0.],\n",
            "       [ 0., 20.,  0., 42.,  0.],\n",
            "       [ 0., 20.,  0., 40.,  1.],\n",
            "       [ 0., 18.,  0., 36.,  1.]], dtype=float32)>, <tf.Tensor: shape=(32, 1), dtype=float32, numpy=\n",
            "array([[4.5415225],\n",
            "       [6.7792144],\n",
            "       [7.1782513],\n",
            "       [7.2510037],\n",
            "       [6.68662  ],\n",
            "       [6.68662  ],\n",
            "       [8.93754  ],\n",
            "       [5.81359  ],\n",
            "       [6.812284 ],\n",
            "       [6.3757687],\n",
            "       [7.687519 ],\n",
            "       [7.7382255],\n",
            "       [8.624484 ],\n",
            "       [8.344497 ],\n",
            "       [7.6257896],\n",
            "       [7.7492485],\n",
            "       [7.6257896],\n",
            "       [6.2831745],\n",
            "       [7.3744626],\n",
            "       [9.237369 ],\n",
            "       [8.9992695],\n",
            "       [7.687519 ],\n",
            "       [7.4560337],\n",
            "       [7.438397 ],\n",
            "       [4.9383545],\n",
            "       [7.7823176],\n",
            "       [5.9039793],\n",
            "       [8.432681 ],\n",
            "       [5.562263 ],\n",
            "       [7.063611 ],\n",
            "       [7.561856 ],\n",
            "       [5.1257477]], dtype=float32)>)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Set up the feature columns for the model."
      ],
      "metadata": {
        "id": "Pvpk78y9u3eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create feature columns to handle categorical variables\n",
        "numeric_columns = [\n",
        "    fc.numeric_column(\"mother_age\"),\n",
        "    fc.numeric_column(\"gestation_weeks\")\n",
        "]\n",
        "\n",
        "CATEGORIES = {\n",
        "    'plurality': list(df.plurality.unique()),\n",
        "    'is_male': list(df.is_male.unique()),\n",
        "    'mother_race': list(df.mother_race.unique())\n",
        "}\n",
        "\n",
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "    cat_col = fc.categorical_column_with_vocabulary_list(\n",
        "        key=feature, vocabulary_list=vocab, dtype=tf.string)\n",
        "    categorical_columns.append(fc.indicator_column(cat_col))"
      ],
      "metadata": {
        "id": "VVgW9ykFumDV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SNN Model Build-Up"
      ],
      "metadata": {
        "id": "TlFiwadCvAKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Inputs for model\n",
        "inputs = {colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.float32)\n",
        "          for colname in [\"mother_age\", \"gestation_weeks\"]}\n",
        "inputs.update({colname: tf.keras.layers.Input(name=colname, shape=(), dtype=tf.string)\n",
        "               for colname in [\"plurality\", \"is_male\", \"mother_race\"]})\n",
        "\n",
        "# Ensure all inputs are in the correct type before combining\n",
        "for key in inputs:\n",
        "    if inputs[key].dtype == tf.string:\n",
        "        inputs[key] = tf.expand_dims(inputs[key], -1)\n",
        "\n",
        "# Build DenseFeatures for the model\n",
        "feature_layer = layers.DenseFeatures(categorical_columns + numeric_columns)\n",
        "dnn_inputs = feature_layer(inputs)\n",
        "\n",
        "# Create hidden layers\n",
        "h1 = layers.Dense(20, activation=\"relu\")(dnn_inputs)\n",
        "h2 = layers.Dense(10, activation=\"relu\")(h1)\n",
        "\n",
        "# Create model\n",
        "output = layers.Dense(1, activation=\"relu\")(h2)\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
        "model.compile(optimizer='Adam',\n",
        "              loss=tf.keras.losses.MeanSquaredError(),\n",
        "              metrics=['mse'])"
      ],
      "metadata": {
        "id": "QM7z7BfaumAy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Overfit on a Batch***"
      ],
      "metadata": {
        "id": "5dW49peMvHad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for feature_batch, label_batch in trainds.batch(5).take(1):\n",
        "    print(\"'babyweight': {}\".format(label_batch))\n",
        "    print(\"features:\")\n",
        "    for key, value in feature_batch.items():\n",
        "      print(\"  {!r:20s}: {}\".format(key, value))"
      ],
      "metadata": {
        "id": "ZlMiqv3Tul_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "single_batch = trainds.batch(BATCH_SIZE).take(1)"
      ],
      "metadata": {
        "id": "d3OOiP5xul7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the classifcation model\n",
        "tf.random.set_seed(33)\n",
        "\n",
        "NUM_TRAINING_EXAMPLES = BATCH_SIZE  # total number of training examples\n",
        "NUM_VALID_EXAMPLES = X_valid.shape[0]\n",
        "NUM_EPOCHS = 100\n",
        "TOTAL_TRAINING_EXAMPLES = int(NUM_EPOCHS * NUM_TRAINING_EXAMPLES)\n",
        "\n",
        "steps_per_epoch = (TOTAL_TRAINING_EXAMPLES // (BATCH_SIZE * NUM_EPOCHS))\n",
        "\n",
        "evalds = evalds.batch(X_valid.shape[0]).take(int(NUM_VALID_EXAMPLES//BATCH_SIZE))\n",
        "\n",
        "# train the model\n",
        "history = model.fit(single_batch.repeat(),\n",
        "                    validation_data=evalds,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    steps_per_epoch=steps_per_epoch,\n",
        "                    verbose=0\n",
        "                   )"
      ],
      "metadata": {
        "id": "zZv15gJLul5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_curves(history, metrics):\n",
        "    nrows = 1\n",
        "    ncols = 2\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "\n",
        "    for idx, key in enumerate(metrics):\n",
        "        ax = fig.add_subplot(nrows, ncols, idx+1)\n",
        "        plt.plot(history.history[key])\n",
        "        plt.plot(history.history['val_{}'.format(key)])\n",
        "        plt.title('model {}'.format(key))\n",
        "        plt.ylabel(key)\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'validation'], loc='upper left');"
      ],
      "metadata": {
        "id": "v-cLba6lul2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_curves(history, ['loss'])"
      ],
      "metadata": {
        "id": "SpcCxSTFulzy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}